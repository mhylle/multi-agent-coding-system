# LLM API Configuration
ANTHROPIC_API_KEY=your_anthropic_api_key_here
OPENAI_API_KEY=your_openai_api_key_here

# LLM Client Configuration
DEFAULT_PROVIDER=anthropic
MAX_RETRIES=3
RETRY_DELAY=1.0
TIMEOUT=60.0
RATE_LIMIT_RPM=50

# Message Bus Configuration
MAX_QUEUE_SIZE=1000
MESSAGE_RETENTION=10000

# Service Registry Configuration
HEALTH_CHECK_INTERVAL=30.0
SERVICE_TIMEOUT=60.0

# Task Manager Configuration
MAX_CONCURRENT_TASKS=50
DEPENDENCY_CHECK_INTERVAL=5.0

# Logging Configuration
LOG_LEVEL=INFO
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s

# Development Configuration
MOCK_LLM_RESPONSES=false
DEBUG_MODE=false